Name: layer1.weight
Shape: torch.Size([1024, 7])
Device: cuda:2
Requires Grad: True
Data Type: torch.float32
Value: Parameter containing:
tensor([[ 1.8907e-01, -3.6148e-01, -5.1705e-02,  ..., -4.2642e-01,
         -5.1748e-02, -4.2819e-02],
        [ 2.0954e-01, -3.6834e-01, -2.8887e-01,  ..., -1.0184e-02,
          5.7753e-02,  2.1171e-01],
        [-1.9018e+00,  2.1072e-01, -3.6660e-01,  ...,  5.8571e-02,
         -9.4251e-02,  2.0715e-02],
        ...,
        [-1.5491e-01, -6.4269e-01, -1.8956e-01,  ..., -1.3595e+00,
         -6.9536e-01, -6.6847e-02],
        [-7.7741e-04, -3.0945e-01, -9.6707e-02,  ..., -2.0625e-01,
         -2.8537e-01,  2.1615e-01],
        [-1.2029e+00,  4.1526e-01, -3.2546e-01,  ...,  5.5188e-01,
         -3.2319e-01, -2.9359e-01]], device='cuda:2', requires_grad=True)

Name: layer1.bias
Shape: torch.Size([1024])
Device: cuda:2
Requires Grad: True
Data Type: torch.float32
Value: Parameter containing:
tensor([ 0.1467, -0.2225, -1.5777,  ...,  0.1372,  0.0781, -0.8142],
       device='cuda:2', requires_grad=True)

Name: layer2.weight
Shape: torch.Size([512, 1024])
Device: cuda:2
Requires Grad: True
Data Type: torch.float32
Value: Parameter containing:
tensor([[-0.0311, -0.0200, -0.0759,  ..., -0.0319,  0.0039, -0.0570],
        [-0.0540, -0.0154,  0.0693,  ..., -0.0748,  0.0161, -0.0706],
        [-0.0486,  0.0268,  0.0753,  ..., -0.0578,  0.0235, -0.0295],
        ...,
        [-0.0714, -0.0023, -0.0372,  ..., -0.0311,  0.0168, -0.0960],
        [ 0.0465, -0.0228, -0.0413,  ...,  0.3954,  0.0086,  0.0779],
        [ 0.0410, -0.0222, -0.0630,  ...,  0.0311, -0.0305, -0.2265]],
       device='cuda:2', requires_grad=True)

Name: layer2.bias
Shape: torch.Size([512])
Device: cuda:2
Requires Grad: True
Data Type: torch.float32
Value: Parameter containing:
tensor([-0.0621, -0.0422, -0.0614, -0.0718, -0.0711, -0.1990, -1.8157, -2.2279,
        -0.0630, -0.0395, -0.1791, -0.0471, -0.0944, -0.2815, -0.1427, -0.1338,
        -2.0703, -0.0730, -0.0785, -0.0559, -2.2446, -1.8600, -0.0900, -0.0520,
        -0.0459, -0.0719, -0.2852, -2.1815, -2.4101, -1.6226, -2.5907, -2.1501,
        -2.3240, -1.7309, -0.0924, -2.3973, -2.2942, -0.0758, -3.0544, -0.0859,
        -2.2050, -0.0424, -0.0371, -2.3363, -0.0630, -0.0541, -2.3377, -2.4587,
        -0.3709, -0.2109, -2.2268, -0.2347, -0.0618, -0.2970, -0.0541, -0.0458,
        -0.2740, -0.0891, -0.0502, -1.3237, -0.0825, -2.0701, -0.0365, -2.3435,
        -0.0603, -0.0695, -2.3683, -0.0478, -2.4936, -2.3803, -0.3490, -0.0494,
        -0.0507, -0.0819, -0.0598, -0.0520, -1.6675, -2.2821, -0.0522, -2.4274,
        -0.0712, -0.0335, -0.0386, -2.0057, -2.4189, -2.3542, -0.0838, -0.0401,
        -2.4903, -0.0532, -1.8694, -1.8024, -0.0986, -0.0537, -2.2102, -0.0311,
        -2.4819, -2.4280, -2.2862, -0.0775, -0.1846, -0.0296, -0.2064, -2.4249,
        -0.0590, -1.9093, -2.0751, -0.1862, -0.1047, -2.1221, -1.4322, -0.0501,
        -2.2567, -0.1545, -0.2006, -0.0388, -0.0337, -0.0547, -2.6011, -1.8160,
        -0.0656, -0.0371, -2.5737, -0.0562, -2.2277, -2.4065, -0.0669, -2.2715,
        -0.0399, -2.2755, -0.3322, -0.0482, -0.0714, -2.2801, -2.2905, -1.9139,
        -0.1919, -0.0330, -1.9089, -0.2186, -0.0337, -2.1692, -2.5965, -2.4027,
        -0.0577, -0.0398, -0.0788, -0.0750, -2.6393, -1.8684, -1.4371, -2.5230,
        -0.2184, -2.3929, -0.0532, -3.0948, -0.0825, -2.3848, -0.0729, -2.4240,
        -2.5561, -2.3865, -0.0520,  0.3411, -0.0537, -0.0321, -2.4308, -2.5399,
        -0.0340, -2.0361, -0.0528, -2.0046, -0.4389, -0.0516, -2.5472, -0.0517,
        -0.0580, -0.0872, -0.0882, -2.3086, -1.7410, -0.0427, -1.0750, -1.2177,
        -0.1692, -0.0846, -0.0862, -2.1184, -0.0718, -1.8127, -0.0583, -0.0819,
        -0.0855, -0.0647, -0.0745, -0.0764, -0.0699, -0.2642, -2.0210, -2.5624,
        -0.0433, -2.3701, -0.1535, -0.0829, -1.5445, -2.4297, -1.8336, -0.0830,
        -0.0759, -0.0678, -0.0997, -2.4114, -2.1574, -2.1099, -0.1072, -0.0655,
        -0.0267, -2.9422, -2.4467, -0.1652, -0.0320, -0.1681, -0.0741, -0.0846,
        -0.0739, -2.5847, -2.5697, -2.0692, -0.0864, -0.0358, -2.2084, -0.0909,
        -2.2821, -0.0609, -2.3958, -0.0599, -1.0101, -0.7672, -2.8915, -1.8085,
        -2.2683, -2.2059, -2.0824, -0.0452, -0.0887, -0.4681, -0.0202, -0.0387,
        -2.4272, -2.3072,  0.1350, -0.0430, -0.0673, -2.2838, -2.3299, -2.5872,
        -1.5069,  0.0254, -0.0884, -0.0402, -1.5670, -0.0654, -0.2498, -2.2927,
        -2.3227, -1.7723, -0.1517, -2.0205, -2.5630, -0.2766, -2.0737, -2.1871,
        -2.3318, -0.0781, -2.2890, -2.4420, -0.0325, -0.0799, -0.0844, -0.0883,
        -0.0616, -0.0802, -0.0487, -2.3789, -2.2296, -0.0819, -0.0875, -0.0639,
        -2.2260, -0.0278, -2.1048, -0.4009, -1.1235, -0.0754, -2.8088, -0.0509,
        -0.0856, -0.0346, -1.9989, -0.0789, -0.0416, -2.4366, -0.0322, -2.0334,
        -0.0396, -0.0555, -2.7606, -0.2724, -0.0900, -3.8511, -1.5480, -0.0321,
        -2.1531, -0.0768,  0.9135, -0.1195, -2.5523, -0.0444, -2.2289, -0.2777,
        -0.5916, -0.1096, -2.0259, -2.0739, -0.0902, -0.0555, -2.3688, -0.0452,
        -0.1679, -1.4747, -1.7695, -0.0852, -0.0494, -2.0251, -0.0541, -0.0333,
        -0.0393, -0.0714, -0.0832, -1.6622, -1.8006, -1.9513, -0.3228, -0.0858,
        -0.0507, -2.2670, -2.0789, -0.1886, -2.1157, -2.3042, -2.0299, -0.0287,
        -0.0873, -0.0403, -0.0395, -0.0349, -1.9445, -0.0708, -1.7570, -2.4369,
        -1.6276, -0.0752, -0.1174, -0.2833, -2.3453, -0.1876,  3.7916, -0.0696,
        -0.0869, -0.1967, -0.0478, -1.9211, -2.4191, -2.3147, -0.0690, -0.0739,
        -2.1738, -0.0618, -0.0475, -1.5046, -0.0705, -0.1846, -2.3533, -2.3992,
        -0.1112, -0.0672, -0.0425, -2.1973, -2.4829, -0.0631, -3.1437, -2.2396,
        -2.3748,  0.2623, -0.0606, -0.0299, -0.0357, -0.0555, -0.3800, -1.9303,
        -0.0751, -0.0791, -0.0795, -2.1897, -0.0641, -0.0808, -0.2686, -1.9150,
        -0.0475, -1.6895, -0.0298, -0.7867, -0.1059, -0.0653, -0.0456, -0.0890,
        -0.0301, -0.0802, -2.2839, -2.3095, -0.2876, -0.0298, -0.0998, -2.5694,
        -2.2101, -2.2337, -0.0659, -2.3536, -2.1615, -0.0751, -2.3421, -1.6295,
        -2.1724, -0.0504, -2.1267, -0.0642, -0.0792, -2.3931, -0.0378, -2.3122,
        -2.0148, -0.0769, -2.5146, -0.0751, -0.0873, -0.0786,  0.0923, -0.7278,
        -0.0458, -1.4472, -0.3531, -2.2413, -0.0868, -0.0580, -0.0445, -0.2855,
        -0.0867, -0.3120, -1.9263, -0.0562, -0.0321, -0.3194, -1.8351, -0.0614,
        -1.8309, -2.1394, -1.8420, -2.6306, -0.0518, -0.0673, -2.1811, -0.0825,
        -0.0785, -2.3715, -2.3844, -0.0908, -2.2126, -0.0344, -0.0447, -2.3917,
        -0.0338, -1.5983, -0.0678, -2.6728, -0.0906, -2.3492, -2.1270, -0.0543,
        -0.0638, -0.1565, -0.0871, -0.0243, -2.2795, -0.0908, -0.1868, -0.0465,
        -3.9357, -2.2644, -0.1775, -0.0828, -2.2436, -2.4535, -0.0440, -0.0327,
         0.6093, -2.1469, -0.2972, -1.9511, -0.0361, -0.1147, -0.3472, -0.3693],
       device='cuda:2', requires_grad=True)

Name: layer3.weight
Shape: torch.Size([128, 512])
Device: cuda:2
Requires Grad: True
Data Type: torch.float32
Value: Parameter containing:
tensor([[ 0.0318, -0.0364, -0.0312,  ...,  0.0770, -0.2516,  0.0072],
        [-0.0049, -0.0278, -0.0076,  ..., -0.0467,  0.0254, -0.0029],
        [-0.0324,  0.0119, -0.0331,  ...,  0.0301, -0.2811,  0.0283],
        ...,
        [-0.0720, -0.0963, -0.1031,  ..., -0.0485, -0.0757, -0.0345],
        [ 0.0910,  0.0291,  0.1036,  ..., -0.0913,  0.0504, -0.0040],
        [-0.0409, -0.0523, -0.0923,  ..., -0.0250, -0.4114,  0.0521]],
       device='cuda:2', requires_grad=True)

Name: layer3.bias
Shape: torch.Size([128])
Device: cuda:2
Requires Grad: True
Data Type: torch.float32
Value: Parameter containing:
tensor([-3.4346, -0.2732, -2.4879, -0.3165, -0.2811, -0.3333, -4.3726, -0.3542,
        -1.3520, -1.9466, -0.8466, -0.0368, -0.0295, -0.2360,  0.4696, -1.1601,
        -0.6633, -1.6422, -0.0507, -0.5540, -1.1505, -0.9505, -1.3947,  1.6321,
         1.5045, -1.5781, -0.4563,  0.8511, -0.1677,  0.5118, -1.3081, -0.2401,
        -0.0435, 11.9924, -0.7662, -0.7010, -0.5037, -0.7858, -0.1092, -0.0362,
        -0.1010, -0.3812, -0.3521,  0.5357, -1.4428, -1.7054, -0.3309, -0.8111,
        -0.5713, -0.4793, -0.9902, -2.2491,  1.3782,  0.3710, -0.2914, -3.8345,
         0.7396, -0.4692, -0.3495, -0.5848, -1.7765, -0.1220, -1.4884, -0.0587,
        -0.0313,  1.1933, -0.6620, -0.5881, -1.3124, -0.0624,  0.1493, -0.0469,
        -0.1871, -0.2778, -0.0736, -0.9998, -0.1053, -1.3510, -0.8906, -0.0332,
        -0.6688, -2.1374, -0.6927, -0.0700, -0.0215, -1.9505, -2.0247,  3.6498,
        -3.2538, -0.5934, -0.7362, -2.1234,  1.2061, -1.7346, -1.3237, -2.3293,
        -0.5082, -1.9494, -1.6764,  1.5706, -0.4842, -0.5415,  0.4289,  0.7079,
        -0.5369,  5.3616, -0.4638, -0.4271, -0.1946, -0.5724, -1.0297, -1.0867,
        -0.5026, -0.6499,  7.1525, -1.7225, -0.0237, -0.2928, -0.1810, -0.4540,
        -0.1860, -0.0604,  0.8910, -0.4041, -2.4418, -0.0589,  0.5431,  0.4982],
       device='cuda:2', requires_grad=True)

Name: layer4.weight
Shape: torch.Size([32, 128])
Device: cuda:2
Requires Grad: True
Data Type: torch.float32
Value: Parameter containing:
tensor([[-0.0587, -0.1417, -0.3022,  ..., -0.0078,  0.0061, -0.2709],
        [-0.5036,  0.0329, -0.0589,  ...,  0.0490,  0.0566, -0.0129],
        [-0.0553,  0.0240, -0.0853,  ..., -0.0007, -0.0542, -0.0051],
        ...,
        [-0.0636,  0.0136, -0.0573,  ...,  0.0370,  0.0410,  0.1444],
        [-0.2023,  0.0968, -0.0412,  ..., -0.3700, -0.0464, -0.0253],
        [ 0.0062,  0.0530, -0.0677,  ..., -0.0896,  0.0210, -0.0671]],
       device='cuda:2', requires_grad=True)

Name: layer4.bias
Shape: torch.Size([32])
Device: cuda:2
Requires Grad: True
Data Type: torch.float32
Value: Parameter containing:
tensor([-0.1303, -0.4316, -0.0401, -0.2923, -0.1829, -0.3334, -0.0598,  1.1295,
        -0.1085, -0.0032, -0.3013, -0.1855, -1.7147, -0.0269, -0.1343,  0.1182,
        -0.1411, -0.1402, -0.4553, -0.1405, -1.3572, -0.3620,  0.0157, -0.0313,
        -0.0661, -0.0692, -0.0121,  0.0173, -0.0790,  0.0755,  0.1450, -0.0749],
       device='cuda:2', requires_grad=True)

Name: layer5.weight
Shape: torch.Size([4, 32])
Device: cuda:2
Requires Grad: True
Data Type: torch.float32
Value: Parameter containing:
tensor([[ 0.1853, -0.1414, -0.0559,  0.3005,  0.0151,  0.0288,  0.2163,  0.0028,
          0.0800, -0.0812, -0.2714,  0.0172, -0.3189,  0.0968,  0.1306,  0.1613,
          0.2126,  0.0556,  0.1164, -0.0627, -0.0403, -0.0824,  0.0262,  0.1450,
          0.1034,  0.0610,  0.2138, -0.1048, -0.3825,  0.0903,  0.1008, -0.0402],
        [-0.0162, -0.2873,  0.0782,  0.4790,  0.3192,  0.0129,  0.2094, -0.0010,
          0.1028,  0.0016,  0.1974, -0.2319, -0.0538, -0.0030,  0.1621,  0.0343,
          0.0314,  0.1065,  0.0157,  0.0510, -0.0211, -0.0237,  0.0789,  0.1208,
          0.1806,  0.2277,  0.1655, -0.3085,  0.1997, -0.0096, -0.0214, -0.1239],
        [-0.0263, -0.3557, -0.0346, -0.2835,  0.1201,  0.2221, -0.0604,  0.2263,
         -0.0490,  0.0399,  0.2393, -0.2563,  0.3378, -0.0156,  0.0255, -0.0384,
          0.3907, -0.0616,  0.1834, -0.0593,  0.0430,  0.0525, -0.0724, -0.1115,
         -0.0381,  0.0375,  0.0263, -0.0756, -0.1482,  0.0246,  0.0025, -0.0559],
        [ 0.2036, -0.2851,  0.0449, -0.1775,  0.0110,  0.1342,  0.1733,  0.0904,
          0.2843, -0.0280,  0.2831, -0.1343, -0.0469,  0.0437,  0.1507, -0.0028,
          0.0672, -0.0740,  0.0298,  0.0153, -0.1782, -0.1872,  0.1554,  0.0113,
          0.1710, -0.1084,  0.0173, -0.0036, -0.0287, -0.0665, -0.0990,  0.1892]],
       device='cuda:2', requires_grad=True)

Name: layer5.bias
Shape: torch.Size([4])
Device: cuda:2
Requires Grad: True
Data Type: torch.float32
Value: Parameter containing:
tensor([9.3459, 0.1947, 0.1517, 2.3623], device='cuda:2', requires_grad=True)

